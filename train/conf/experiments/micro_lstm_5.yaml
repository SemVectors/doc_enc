# @package _global_
defaults:
  - /base_config
  - override /trainer: quick
  - override /trainer/optim: adam_with_one_cycle
  - _self_

text_proc:
  tokenizer:
    vocab_path: /train/unigram_96k_from_100M.spm.model

model:
  split_size: 2048
  scale: 20
  margin: 0.0
  sent:
    scale: 20
    margin: 0.3
  doc:
    input_size: 1024
    hidden_size: 512

batches:
  sents_batch_iterator_conf:
    async_generators: 1
    batch_generator_conf:
      batch_size: 1024

  docs_batch_iterator_conf:
    async_generators: 2
    include_datasets:
      - pw
      - sew
      - srw
    batch_generator_conf:
      positives_per_doc: [1, 4]
      batch_src_sents_cnt: 26384
      batch_total_sents_cnt: 30384
      batch_size: 256
      max_sents_per_doc: 1024
